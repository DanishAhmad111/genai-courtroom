version: '3.8'

services:
  genai-courtroom:
    build: .
    container_name: genai-courtroom
    ports:
      - "8501:8501"
    environment:
      - CHATGROQ_API_KEY=${CHATGROQ_API_KEY}
      - USE_LOCAL_JUDGE=${USE_LOCAL_JUDGE:-false}
      - JUDGE_LORA_PATH=${JUDGE_LORA_PATH:-judge-lora}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      # Persist FAISS embeddings
      - ./rag/embeddings:/app/rag/embeddings
      # Optional: Mount model cache for faster restarts
      - huggingface-cache:/root/.cache/huggingface
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  huggingface-cache:
    driver: local
