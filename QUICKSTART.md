# üöÄ Quick Deployment Guide

## TL;DR - Deploy in 3 Steps

### 1Ô∏è‚É£ Upload Model to HuggingFace

```bash
pip install huggingface-hub
huggingface-cli login
python scripts/upload_model_to_hf.py --repo_name YOUR_USERNAME/genai-courtroom-judge
```

### 2Ô∏è‚É£ Push to GitHub

```bash
git add .
git commit -m "Ready for deployment"
git push origin main
```

### 3Ô∏è‚É£ Deploy to Streamlit Cloud

1. Go to [share.streamlit.io](https://share.streamlit.io)
2. Click "New app" ‚Üí Select your repo
3. Add secrets:
   ```toml
   CHATGROQ_API_KEY = "your_groq_api_key"
   USE_LOCAL_JUDGE = "true"
   JUDGE_LORA_PATH = "YOUR_USERNAME/genai-courtroom-judge"
   ```
4. Click "Deploy!"

---

## üìã Pre-Deployment Checklist

- [ ] Have Groq API key ([Get one](https://console.groq.com))
- [ ] Have HuggingFace account ([Sign up](https://huggingface.co/join))
- [ ] Code pushed to GitHub
- [ ] Model uploaded to HuggingFace
- [ ] `.env.example` copied to `.env` locally for testing

---

## üîë Required Secrets/Environment Variables

```toml
CHATGROQ_API_KEY = "gsk_..."           # From console.groq.com
USE_LOCAL_JUDGE = "true"                # Enable fine-tuned model
JUDGE_LORA_PATH = "username/model-name" # Your HF model path
```

---

## üß™ Test Locally First (Optional)

```bash
# Using Docker Compose
docker-compose up

# Or using Streamlit directly
streamlit run streamlit_app.py
```

Visit [http://localhost:8501](http://localhost:8501)

---

## üåê Platform Comparison

| Platform | Difficulty | Free Tier | Best For |
|----------|-----------|-----------|----------|
| **Streamlit Cloud** | ‚≠ê Easy | 1GB RAM | Quick demos |
| **Railway** | ‚≠ê‚≠ê Medium | $5 credit | Production |
| **Render** | ‚≠ê‚≠ê Medium | 512MB RAM | Docker apps |
| **HF Spaces** | ‚≠ê‚≠ê‚≠ê Hard | 16GB RAM | ML models |

**Recommendation**: Start with Streamlit Cloud, upgrade to Railway for production.

---

## ‚ö° Common Issues & Fixes

### "Model not found"
‚Üí Check HuggingFace model URL is correct  
‚Üí Make model public or add `HF_TOKEN`

### "Out of memory"
‚Üí Upgrade to paid tier  
‚Üí Or set `USE_LOCAL_JUDGE=false` (use only Groq API)

### "Slow first load"
‚Üí Normal! Model downloading takes 5-10 minutes  
‚Üí Subsequent loads will be faster

---

## üìñ Full Documentation

- **Detailed Guide**: [DEPLOYMENT.md](DEPLOYMENT.md)
- **Project Info**: [README.md](README.md)
- **Complete Walkthrough**: See artifacts

---

**Need help?** Check [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions.
